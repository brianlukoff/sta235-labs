{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brianlukoff/sta235-labs/blob/main/labs/01_linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can run cells in a notebook by hovering the mouse over the `[ ]` on the left side of the cell, which should turn into a \"play\" button. Then click the button to run the code.\n",
        "\n",
        "All cells are editable by you at any time -- you can always change the code and rerun the code to see the effect. In some cells you'll see blanks and we'll ask you to figure out what code is needed to fill in the blanks to get the desired output."
      ],
      "metadata": {
        "id": "qBLXLR1qYz0w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aV2N542wf4jQ",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# We will use tidyverse for a lot of our data manipulations. (It's okay to get warnings!)\n",
        "# You don't need to use any other \"library\" commands unless you are using a special function that is only available in a certain \"package\" (we'll tell you when that comes up).\n",
        "library(tidyverse)\n",
        "source(\"https://github.com/brianlukoff/sta235-labs/raw/main/src/common.R\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Exploration"
      ],
      "metadata": {
        "id": "uO5LljuNmDOo",
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The head() function gives the first few rows of a dataframe\n",
        "profs %>% head()"
      ],
      "metadata": {
        "id": "fTfPyGuvgVlq",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's explore some of our variables. Here's a histogram of the `eval` variable."
      ],
      "metadata": {
        "id": "FmyQq3oZg08q",
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ggplot(data=profs) +\n",
        "  geom_histogram(aes(x=eval), bins=10, color='white')"
      ],
      "metadata": {
        "id": "1qJ1o88QgZ3v",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's try it for attractiveness. Fill in the blank with the appropriate variable name."
      ],
      "metadata": {
        "id": "MR9X9YLJha2s",
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ggplot(data=profs) +\n",
        "  geom_histogram(aes(x=____________), bins=10, color='white')"
      ],
      "metadata": {
        "id": "lAw3GAfXhDV_",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is there a relationship between attractiveness and evaluation? Let's look at a scatterplot. Fill in `x` and `y` with the variables you want to look at."
      ],
      "metadata": {
        "id": "QXNsiggyhxKB",
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ggplot(data=profs) +\n",
        "  geom_point(aes(x=____________, y=_____________))"
      ],
      "metadata": {
        "id": "6suhhwSwhvqu",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plot indicates that there might be some association between the two. We can measure that association with the correlation coefficient. Recall that this measures the strength of a linear relationship between two variables. The `cor` function in R gives us this. The `$` tells R to look in the `profs` data for the variable name that follows."
      ],
      "metadata": {
        "id": "A9az5ET-iMUj",
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cor(profs$beauty, profs$eval)"
      ],
      "metadata": {
        "id": "TnMXUFN2iKv2",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression"
      ],
      "metadata": {
        "id": "_okl_e8JjXON",
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear regression is a technique that finds the line of best fit that maps `x` onto `y`.  In other words, we're modeling the true relationship\n",
        "\n",
        "$Y=\\beta_0 + \\beta_1 X + \\varepsilon$\n",
        "\n",
        "with our best estimates\n",
        "\n",
        "$\\hat Y = \\hat\\beta_0 + \\hat\\beta_1 X$ (the hats indicate estimates)\n",
        "\n",
        "In R, the `lm()` function finds the intercept $\\hat\\beta_0$ and slope $\\hat\\beta_1$ that make the line best fit the data."
      ],
      "metadata": {
        "id": "dPZ1izZljZjP",
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a regression model\n",
        "lm1 <- lm(eval ~ beauty, data=profs) # this saves the model into an object called lm1\n",
        "summary(lm1) # this prints out the results of our regression"
      ],
      "metadata": {
        "id": "rSO89HgekRd8",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What does this fitted line look like when plotted on our data?"
      ],
      "metadata": {
        "id": "XJtphNS4lqJJ",
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ggplot(data=profs) +\n",
        "  geom_point(aes(x=beauty, y=eval))+\n",
        "  geom_smooth(aes(x=beauty, y=eval), method='lm', se=FALSE)"
      ],
      "metadata": {
        "id": "LQEkqS9BiryD",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The line goes through the points, sure, but there seems to be a lot of variation around it. How certain are we of our estimates of the parameters of this line?"
      ],
      "metadata": {
        "id": "Vo9uTFNX6Y5b",
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confidence intervals for coefficients\n",
        "\n",
        "We can create a confidence interval for model coefficients using the function `confint()`:"
      ],
      "metadata": {
        "id": "2Aw49cJOqkTH",
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confint(lm1)"
      ],
      "metadata": {
        "id": "qguaLmwAmbWt",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the output above, what can we conclude about the coefficient for beauty?\n",
        "\n",
        "A. We are 95% confident the impact of each additional point of beauty on evaluation score is between 3.95 and 4.05.\n",
        "\n",
        "B. The impact of each additional point of beauty on evaluation score is between 3.95 and 4.05.\n",
        "\n",
        "C. We are 95% confident the impact of each additional point of beauty on evaluation score is between 0.07 and 0.20.\n",
        "\n",
        "D. The impact of each additional point of beauty on evaluation score is between 0.07 and 0.20.\n",
        "\n",
        "Check your answer by replacing the blank below with `A`, `B`, `C`, or `D` and running the code:"
      ],
      "metadata": {
        "id": "30KYm9T1iXkE",
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lab_1_question_1(\"____\")"
      ],
      "metadata": {
        "id": "IlRKmWCGjipo",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confidence intervals for predictions\n",
        "\n",
        "Linear regressions are very easy to use to make predictions. We take the estimates from our summary table, and just write out an equation and plugin the value of interest for which we want a prediction. Our equation is"
      ],
      "metadata": {
        "id": "_nVFfpOarMf3",
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill in the correct coefficients below to obtain a prediction for `eval` when `beauty` is 0.5\n",
        "______ + ______ * 0.5"
      ],
      "metadata": {
        "id": "76QUHWeYqvG8",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Then fill in your answer here to check it.\n",
        "lab_1_question_2(____)"
      ],
      "metadata": {
        "id": "NmE9GNqff3zW",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we want a bit more precision (and less copy pasting) we can use R's built in `predict()` function. The `predict()` function takes a model object as the first argument, and values of $X$ to be used by that model as a second argument. Below, try predicting the evaluation score for a somewhat attractive professor with a beauty score of 0.5 and see that you get the same answer as you did above:"
      ],
      "metadata": {
        "id": "QHP1nm-SuYJL",
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plug in different values of beauty\n",
        "predict(lm1, list(beauty=_____))"
      ],
      "metadata": {
        "id": "NLTt-FzArLxf",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes we want to know how confident we are in our predictions. For this, we can extend the predict function with a third argument. The `interval` argument can take \"prediction\" for prediction intervals for an individual response and \"confidence\" for confidence intervals for a mean response. Compare the two below. Which one is wider?"
      ],
      "metadata": {
        "id": "0_lZ-Kug5w4l",
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict(lm1, list(beauty=0.5), interval=\"prediction\")"
      ],
      "metadata": {
        "id": "dAzE7njT5vRx",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(lm1, list(beauty=0.5), interval=\"confidence\")"
      ],
      "metadata": {
        "id": "epVGDF2N5p5U",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical significance of the model\n",
        "\n",
        "We know that there is a **statistically significant** relationship between `beauty` and `eval`, so we can be highly confident they are indeed related in the larger population. But it that relationship *meaningful*?\n",
        "\n",
        "Look at the summary of the model again, and look for `Multiple R-squared`. This number, which we'll always call $R^2$, indicates the proportion of the variation in $Y$ which is explained by the model."
      ],
      "metadata": {
        "id": "ITeppmpH8_Wb",
        "pycharm": {
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary(lm1)"
      ],
      "metadata": {
        "id": "pF-fkFIw9-P7",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* It's always true that $0 \\leq R^2 \\leq 1$.\n",
        "* $R^2 = 1$ when the model's predictions of $Y$ are exactly right for each observation. (The best!)\n",
        "* $R^2 = 0$ when the model's predictions of $Y$ are totally unrelated to $Y$. (The worst!)\n",
        "\n",
        "Which of these is true about this model?\n",
        "\n",
        "A. Beauty scores can explain about 5% of the variation in student evaluations.\n",
        "\n",
        "B. Beauty scores can explain about 50% of the variation in student evaluations.\n",
        "\n",
        "C. Beauty scores can explain about 95% of the variation in student evaluations.\n",
        "\n",
        "D. This model will do a very precise job of predicting student evaluations."
      ],
      "metadata": {
        "id": "EIom_f2XgqFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill in your answer here to check it.\n",
        "lab_1_question_3(\"____\")"
      ],
      "metadata": {
        "id": "CAzwK-OSh_2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$R^2$ is helpful to get a sense of how good models are relatively speaking, but it's hard to interpret on its own. Another approach is to look at the residuals.\n",
        "\n",
        "Make a histogram of the residuals, and then calculate the mean and standard deviation."
      ],
      "metadata": {
        "id": "JIwGqGJLiGsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ggplot(data=profs) +\n",
        "  geom_histogram(aes(x=residuals(lm1)))"
      ],
      "metadata": {
        "id": "6lCA9OsQid_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean(residuals(lm1))"
      ],
      "metadata": {
        "id": "XYMmx2lDjPZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sd(residuals(lm1))"
      ],
      "metadata": {
        "id": "tqvthpCKjRVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You found that:\n",
        "\n",
        "* The residuals are approximately Normally distributed. (Remember that the Normal distribution is the \"bell curve\" from STA 301.)\n",
        "\n",
        "* They have a mean of about 0. In other words, positive and negative prediction errors cancel each other out.\n",
        "\n",
        "* They have a standard deviation of about 0.55.\n",
        "\n",
        "Either positive or negative prediction errors are bad (a residual of 0 would be a perfect prediction!).\n",
        "\n",
        "You may remember from STA 301 that about 95% of observations in a Normal distribution fall within +/- 2 standard deviation of the mean.\n",
        "\n",
        "This means that 95% of the time, the prediction errors that the model makes will be within ____ evaluation score points of the correct evaluation score."
      ],
      "metadata": {
        "id": "b4OODtJjie6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Do the calculation by filling in the blank below, and then run the cell to check your answer.\n",
        "lab_1_question_4(_____)"
      ],
      "metadata": {
        "id": "OBnksWSDkW-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Think about the statement above about the prediction errors, and the $R^2$ value you found. What does it tell you about how **practically significant** (i.e., practically useful) this model would be?"
      ],
      "metadata": {
        "id": "V6mlT9c1k9H1"
      }
    }
  ]
}